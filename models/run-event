#!/usr/bin/env python3

"""
Runs a complete heavy-ion collision event:

    - initial condition
    - hydro
    - Cooper-Frye sampler
    - UrQMD afterburner

Saves all results in HDF5 file 'results.hdf'.  Dataset 'initial' contains the
initial entropy profile and has attributes for impact parameter, npart, mult,
and eccentricities.  Groups 'particles/n' (n = integer) contain particle data
for each oversample as datasets ID, charge, mass, pT, phi, eta.

If an argument is passed, it is read as a configuration file with simple
key = value syntax.  Currently the only known keys are 'ic_args' and
'hydro_args'.  The values are passed as arguments directly to the initial
condition and hydro programs.
"""

import itertools
import os
import sys
import subprocess

import numpy as np
import h5py


def run_cmd(*args, **kwargs):
    """
    Run a subprocess, concatenating argument strings together.

    """
    print(*args)
    subprocess.check_call(
        itertools.chain.from_iterable(a.split() for a in args),
        **kwargs
    )


def main():
    # parse config file
    if len(sys.argv) == 2:
        with open(sys.argv[1], 'r') as f:
            config = dict((i.strip() for i in l.split('=', maxsplit=1))
                          for l in f)
    else:
        config = {}

    results_file = 'results.hdf'

    #
    # run models
    #

    # initial condition
    run_cmd('./bin/trento', 'Pb Pb 1 --grid-max 13.05 --grid-step 0.1',
            '--output {}'.format(results_file), config.get('ic_args', ''))

    with h5py.File(results_file, 'r+') as f:
        # rename the IC dataset
        f.move('event_0', 'initial')
        # write the profile in plain text for input to vishnew
        np.savetxt('vishnew/initial.dat', f['initial'], fmt='%.12g')
        # save mult for later use
        mult = f['initial'].attrs['mult']

    # hydro
    run_cmd('./vishnew', config.get('hydro_args', ''), cwd='vishnew')

    # an empty hypersurface file means the IC was too cold to produce any
    # particles from Cooper-Frye, so just end the event here
    if os.stat('vishnew/surface.dat').st_size == 0:
        print('empty hypersurface')
        return

    # move the hypersurface file for input to the sampler
    os.rename('vishnew/surface.dat', 'sampler/surface.dat')

    # sampler
    # estimate number of oversamples from IC mult
    oversamples = min(max(int(5e4/mult), 2), 100)
    run_cmd('./sampler oversamples={}'.format(oversamples), cwd='sampler')

    # hadronic afterburner
    run_cmd('./afterburner ../sampler/oscar.dat final.dat',
            cwd='urqmd-afterburner')

    #
    # save particle data
    #

    # define particle data names and types
    names, dtypes = zip(
        ('ID',     np.int32),
        ('charge', np.int32),
        ('mass',   np.float64),
        ('pT',     np.float64),
        ('phi',    np.float64),
        ('eta',    np.float64),
    )

    # parse urqmd output and write to the HDF5 results file
    with open('urqmd-afterburner/final.dat', 'rb') as f, \
            h5py.File(results_file, 'r+') as results:
        # create an HDF5 group for all particle data
        particles_group = results.create_group('particles')

        # break urqmd output into "event" chunks by splitting on headers
        events = (event for is_header, event in
                  itertools.groupby(f, lambda x: x.startswith(b'#'))
                  if not is_header)

        for n, event in enumerate(events):
            # create a numbered HDF5 group for this event
            event_group = particles_group.create_group(str(n))

            # transpose the event lines into columns
            columns = zip(*(i.split() for i in event))

            # save each column as a 1D dataset
            # lzf compression is very fast, see http://www.h5py.org/lzf
            for name, dtype, column in zip(names, dtypes, columns):
                data = np.array(column, dtype=dtype)
                event_group.create_dataset(name, data=data, compression='lzf')


if __name__ == "__main__":
    main()
