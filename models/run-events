#!/usr/bin/env python3

"""
Runs several complete heavy-ion collision events:

  - initial condition
  - hydro
  - Cooper-Frye sampler
  - UrQMD afterburner

Saves all results in HDF5 file 'results.hdf' with hierarchy:

  - Top-level numbered groups for each event.
  |
  | - Dataset 'initial' contains the initial entropy profile and has
  |   attributes for impact parameter, npart, mult, and eccentricities.
  |
  | - Group 'particles' contains all particle data, if any particles were
    | emitted.
    |
    | - Numbered groups for each oversample, each containing datasets:
      | - ID
      | - charge
      | - mass
      | - pT
      | - phi
      | - eta

If an argument is passed, it is read as a configuration file with simple
key = value syntax.  Currently the only known keys are 'ic_args' and
'hydro_args'.  The values are passed as arguments directly to the initial
condition and hydro programs.
"""

import itertools
import os
import sys
import subprocess

import numpy as np
import h5py


def run_cmd(*args, **kwargs):
    """
    Run a subprocess, concatenating argument strings together.

    """
    print(*args)
    subprocess.check_call(
        list(itertools.chain.from_iterable(a.split() for a in args)),
        **kwargs
    )


def _run_event(event_group, **config):
    """
    Run a complete event.

    Start with the initial condition dataset in the given HDF5 event group.
    Save all particle data to the same HDF5 group.

    """
    # write the profile in plain text for input to vishnew
    np.savetxt('vishnew/initial.dat', event_group['initial'], fmt='%.12g')

    # hydro
    run_cmd('./vishnew', config.get('hydro_args', ''), cwd='vishnew')

    # an empty hypersurface file means the IC was too cold to produce any
    # particles from Cooper-Frye, so just end the event here
    if os.stat('vishnew/surface.dat').st_size == 0:
        print('empty hypersurface')
        return

    # move the hypersurface file for input to the sampler
    os.rename('vishnew/surface.dat', 'sampler/surface.dat')

    # sampler
    # estimate number of oversamples from IC mult
    mult = event_group['initial'].attrs['mult']
    noversamples = min(max(int(1e5/mult), 2), 100)
    run_cmd('./sampler oversamples={}'.format(noversamples), cwd='sampler')

    # A non-empty hypersurface can still emit zero particles.  If no events
    # produced any particles, the sampler output will contain the three-line
    # OSCAR header and nothing else.  In this case end the event here.
    with open('sampler/oscar.dat', 'rb') as f:
        if next(itertools.islice(f, 3, None), None) is None:
            print('no particles emitted')
            return

    # hadronic afterburner
    run_cmd('./afterburner ../sampler/oscar.dat final.dat',
            cwd='urqmd-afterburner')

    # parse urqmd output and write to the HDF5 results file
    with open('urqmd-afterburner/final.dat', 'rb') as f:
        # create an HDF5 group for all particle data
        particles_group = event_group.create_group('particles')

        # break urqmd output into oversamples by splitting on headers
        oversamples = (group for is_header, group in
                       itertools.groupby(f, lambda x: x.startswith(b'#'))
                       if not is_header)

        # define particle data names and types
        names, dtypes = zip(
            ('ID',     np.int32),
            ('charge', np.int32),
            ('mass',   np.float64),
            ('pT',     np.float64),
            ('phi',    np.float64),
            ('eta',    np.float64),
        )

        for n, oversample in enumerate(oversamples):
            # create a numbered HDF5 group for this oversample
            grp = particles_group.create_group(str(n))

            # transpose the event lines into columns
            columns = zip(*(i.split() for i in oversample))

            # save each column as a 1D dataset
            # lzf compression is very fast, see http://www.h5py.org/lzf
            for name, dtype, column in zip(names, dtypes, columns):
                data = np.array(column, dtype=dtype)
                grp.create_dataset(name, data=data, compression='lzf')

        # There may be events that did not produce any particles; in this case
        # the event number (n) will be less than the number of oversamples.
        # Create an empty dataset for each of these events.
        for n in range(n+1, noversamples):
            grp = particles_group.create_group(str(n))
            for name, dtype in zip(names, dtypes):
                grp.create_dataset(name, shape=(0,), dtype=dtype)


def run_events(hdf5_file, **config):
    """
    _run_event wrapper to catch subprocess exceptions and yield True/False.

    """
    for name, group in hdf5_file.items():
        try:
            _run_event(group, **config)
        except subprocess.CalledProcessError as e:
            print('event', name, 'failed:',
                  'command', ' '.join(e.cmd), 'returned', e.returncode,
                  file=sys.stderr)
            # delete group for the failed event
            del hdf5_file[name]
            yield False
        else:
            yield True


def main():
    # parse config file
    if len(sys.argv) == 2:
        with open(sys.argv[1], 'r') as f:
            config = dict((i.strip() for i in l.split('=', maxsplit=1))
                          for l in f)
    else:
        config = {}

    results_file = 'results.hdf'

    # initial condition
    run_cmd('./bin/trento Pb Pb 10',
            '--cross-section 6.4 --grid-max 13.05 --grid-step 0.1',
            '--output {}'.format(results_file), config.get('ic_args', ''))

    with h5py.File(results_file, 'r+') as f:
        # move the IC datasets into event subgroups
        for n, dset in enumerate(f):
            f.move(dset, '{}/initial'.format(n))

        # run each event and save exit status
        status = list(run_events(f, **config))

    print('{}/{}'.format(sum(status), len(status)),
          'events finished successfully')

    # exit failure if no events completed
    if not any(status):
        sys.exit(1)


if __name__ == "__main__":
    main()
